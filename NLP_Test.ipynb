{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMunAksg9xPbLk5I1+ixKqR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sesna-tomy/scifor/blob/main/NLP_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What you understand by Text Processing? Write a code to perform text processing**\n",
        "\n",
        "Text processing refers to the manipulation and analysis of textual data to extract meaningful information or to transform the text in a useful way. This includes tasks such as cleaning and preprocessing text data, tokenization, stemming, lemmatization, part-of-speech tagging, and more."
      ],
      "metadata": {
        "id": "1cMOvxM1Zt65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from  nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP4_NEHvapUx",
        "outputId": "012c8c51-36d2-4033-e4e0-b5494fb39994"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizing and removing stopwords\n",
        "\n",
        "text= \"stopwords are common words that are often removed from text during the preprocessing phase of natural language processing tasks because they are considered to carry little meaning.\"\n",
        "tokens = word_tokenize(text)\n",
        "sw = stopwords.words('english')\n",
        "stopwords_removed = [word for word in tokens if word.lower() not in sw]\n",
        "print(tokens)\n",
        "print(stopwords_removed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-fQeyzsaSp_",
        "outputId": "df0105f4-7133-4c16-a3c9-acb5cb0c671b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['stopwords', 'are', 'common', 'words', 'that', 'are', 'often', 'removed', 'from', 'text', 'during', 'the', 'preprocessing', 'phase', 'of', 'natural', 'language', 'processing', 'tasks', 'because', 'they', 'are', 'considered', 'to', 'carry', 'little', 'meaning', '.']\n",
            "['stopwords', 'common', 'words', 'often', 'removed', 'text', 'preprocessing', 'phase', 'natural', 'language', 'processing', 'tasks', 'considered', 'carry', 'little', 'meaning', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What you understand by NLP toolkit and spacy library? Write a code in which any one gets used.**\n",
        "\n",
        "\n",
        "Natural Language Toolkit and SpaCy are libraries that provide pre-built tools and resources for working with natural language text. They typically include functions for tasks such as tokenization, part-of-speech tagging, named entity recognition, and more. SpaCy is known for its efficiency and speed."
      ],
      "metadata": {
        "id": "WFc86UOiazpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Name Entity Recoginition by spacy\n",
        "\n",
        "import spacy\n",
        "spc = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"In Paris, John Smith attended a conference on artificial intelligence last Friday at 9.30 pm.\"\n",
        "doc = spc(text)\n",
        "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "print(entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSuG8IPLb4mK",
        "outputId": "873c7cc5-11c7-4684-e92a-a92f63e39328"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Paris', 'GPE'), ('John Smith', 'PERSON'), ('last Friday', 'DATE'), ('9.30 pm', 'TIME')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Describe Neural Networks and Deep Learning in Depth**\n",
        "\n",
        "Neural networks are a fundamental component of deep learning. These networks are inspired by the structure and functioning of the human brain, consisting of interconnected nodes (neurons) organized in layers. Neural networks are used to model and solve a variety of complex tasks by learning from data. Neurons are the basic units of a neural network.\n",
        "Neural networks are organized into layers.The three main types of layers are\n",
        "\n",
        "Input Layer- Receives the initial input data.\n",
        "\n",
        "Hidden Layers- Intermediate layers between the input and output layers where the neural network learns representations and features from the data.                                                                           \n",
        "Output Layer- Produces the final output or prediction.\n",
        "\n",
        "Deep learning is a branch of machine learning which is based on artificial neural networks. It is capable of learning complex patterns and relationships within data\n",
        "\n",
        "Deep Neural Networks (DNNs): Neural networks with multiple hidden layers are referred to as deep neural networks. The depth allows these networks to capture hierarchical features and representations in the data, making them well-suited for complex tasks.\n",
        "\n",
        "Convolutional Neural Networks (CNNs): CNNs are specialized neural networks designed for processing grid-like data, such as images. They use convolutional layers to automatically and adaptively learn spatial hierarchies of features.\n",
        "\n",
        "Recurrent Neural Networks (RNNs): RNNs are designed for sequential data, incorporating recurrent connections to capture dependencies over time. They are commonly used in natural language processing and time series analysis.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9SskJhh0gRSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.what you understand by Hyperparameter Tuning?**\n",
        "\n",
        "\n",
        "Hyperparameter tuning is the process of finding the best set of hyperparameters for a machine learning model to optimize its performance. The process of hyperparameter tuning involves systematically trying different combinations of hyperparameter values to find the configuration that results in the best performance on a validation set or through cross-validation. This helps to improve the perfomance of the model."
      ],
      "metadata": {
        "id": "PEfFPdWqcmhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. What you understand by Ensemble Learning?**\n",
        "\n",
        "\n",
        "Ensemble Learning is a machine learning technique that involves combining the predictions of multiple models to improve overall performance and generalization."
      ],
      "metadata": {
        "id": "YKx8V8Pwdf7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What do you understand by Model Evaluation and Selection ?**\n",
        "\n",
        "\n",
        "Model evaluation and selection are steps in the machine learning that assess the performance of different models and choosing the best-performing model for a task. This helps us the select the best model that performs well with unseen data."
      ],
      "metadata": {
        "id": "SOXfexhceoH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. What you understand by Feature Engineering and Feature selection? What is the difference between them?**\n",
        "\n",
        "**Feature engineering** is the process of creating new features or transforming existing features in a dataset to improve the performance of a machine learning model.\n",
        "\n",
        "**Feature selection** is the process of choosing the most important features from the original set of features in a dataset. It reduce dimensionality."
      ],
      "metadata": {
        "id": "efsC4EP9fN2x"
      }
    }
  ]
}